{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ../checkpoints/audio\n",
    "# !pip install gdown\n",
    "# !gdown -O ../checkpoints/audio/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_it_talk.models.audio_to_embedding import AudioToEmbedding\n",
    "import os\n",
    "\n",
    "a = AudioToEmbedding(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from make_it_talk.data.dataloader import parse_lb_tensor, parse_sf_tensor\n",
    "filename = 'D:\\STUDY\\Sirius\\\\barboskini\\\\audio\\\\00000.wav'\n",
    "lb = parse_lb_tensor(filename)\n",
    "\n",
    "file_dir = 'D:\\STUDY\\Sirius\\\\barboskini\\\\audio' \n",
    "file = '00000'\n",
    "sf = parse_sf_tensor(file_dir, file)\n",
    "\n",
    "import torch\n",
    "batch_size = 2\n",
    "audio_spk_tens = torch.stack([lb] * batch_size)\n",
    "audio_cnt_tens = torch.stack([sf] * batch_size)\n",
    "\n",
    "content_emb, speaker_emb = a((audio_spk_tens, audio_cnt_tens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "launch with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_it_talk.data.dataloader import AudioVideoImageTensorDataset\n",
    "import os\n",
    "\n",
    "path_to_working_dir = 'D:\\STUDY\\Sirius'\n",
    "dts = AudioVideoImageTensorDataset(\n",
    "    os.path.join(path_to_working_dir, 'obama', 'audio'),\n",
    "    os.path.join(path_to_working_dir, 'obama', 'video'),\n",
    "    os.path.join(path_to_working_dir, 'obama', 'image')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataloader = torch.utils.data.DataLoader(dts, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\resemblyzer\\audio.py:33: FutureWarning: Pass orig_sr=44100, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  wav = librosa.resample(wav, source_sr, sampling_rate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Video D:\\STUDY\\Sirius\\obama\\video\\00000.mp4, len: 6012, FPS: 29.97, W X H: 1920 x 1080\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video torch.Size([1, 6012, 256, 256, 3])\n",
      "audio_content torch.Size([1, 8846336, 2])\n",
      "audio_speacker torch.Size([1, 2595360])\n",
      "start_image torch.Size([1, 1080, 1920, 3])\n"
     ]
    }
   ],
   "source": [
    "# батчи в таком формате:\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\STUDY\\Sirius\\git_repo\\MakeItTalkReplication\\notebooks\\..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "from make_it_talk.models.composite_models import make_talking_head_pipeline_with_params\n",
    "\n",
    "filepath = os.path.join(os.getcwd(), '..') # если запускаешься из этого ноутбука\n",
    "print(filepath)\n",
    "model = make_talking_head_pipeline_with_params(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "batch_spk = torch.tensor(batch['audio_speacker'])\n",
    "batch_cont = torch.tensor(batch['audio_content'])\n",
    "batch_img = torch.tensor(batch['start_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cpu in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\resemblyzer\\audio.py:52: FutureWarning: Pass y=[-0.00056201 -0.00053132 -0.00064725 ...  0.          0.\n",
      "  0.        ], sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  n_mels=mel_n_channels\n",
      "c:\\Users\\Danill\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\resemblyzer\\audio.py:52: FutureWarning: Pass y=[-0.00016109 -0.00041208 -0.00036738 ...  0.          0.\n",
      "  0.        ], sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  n_mels=mel_n_channels\n",
      "d:\\study\\sirius\\git_repo\\makeittalkreplication\\make_it_talk\\utils\\audio_utils.py:36: FutureWarning: Pass sr=16000, n_fft=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = mel(16000, 1024, fmin=90, fmax=7600, n_mels=80).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 4096, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 4096, 257])\n",
      "source shape: torch.Size([1, 1792, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 1792, 257])\n",
      "converted shape: torch.Size([1, 34560, 80]) torch.Size([1, 3584])\n",
      "MLP_CONT:  torch.Size([1, 34557, 256]) torch.Size([1, 136])\n",
      "MLP_CONT_x:  tensor([[[-4.6722e-02,  2.9998e-02, -1.4547e-02,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02],\n",
      "         [-4.7140e-02,  2.9117e-02,  2.4737e-02,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02],\n",
      "         [-3.1690e-02, -6.7813e-03,  2.7389e-02,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02],\n",
      "         ...,\n",
      "         [ 5.2795e-02,  6.7970e-02,  9.6594e-02,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02],\n",
      "         [ 4.7525e-02,  5.3430e-02,  9.2107e-02,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02],\n",
      "         [ 3.3258e-02,  5.9132e-02,  1.0039e-01,  ...,  5.7300e+02,\n",
      "           9.4100e+02,  5.7300e+02]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ans = model((batch_spk, batch_cont), batch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 34557, 136])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# предсказанные ландмарки\n",
    "ans[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a35fb83ac8e6ec7d775c8e4493051254ee64ddb3600bc3fef060a4811657ed17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
